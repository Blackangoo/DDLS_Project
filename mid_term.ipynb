{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_read_data(alg):\n",
    "    print(alg)\n",
    "    hf = h5py.File(\"./results_2/\"+'{}.h5'.format(alg), 'r')\n",
    "    rs_glob_acc = np.array(hf.get('rs_glob_acc')[:])\n",
    "    rs_train_acc = np.array(hf.get('rs_train_acc')[:])\n",
    "    rs_train_loss = np.array(hf.get('rs_train_loss')[:])\n",
    "    return rs_train_acc, rs_train_loss, rs_glob_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data_value(num_users=100, loc_ep1=5, Numb_Glob_Iters=10, lamb=[], learning_rate=[],beta=[],algorithms_list=[], batch_size=[], dataset=\"\", k= [] , personal_learning_rate = []):\n",
    "    Numb_Algs = len(algorithms_list)\n",
    "    train_acc = np.zeros((Numb_Algs, Numb_Glob_Iters))\n",
    "    train_loss = np.zeros((Numb_Algs, Numb_Glob_Iters))\n",
    "    glob_acc = np.zeros((Numb_Algs, Numb_Glob_Iters))\n",
    "    algs_lbl = algorithms_list.copy()\n",
    "    for i in range(Numb_Algs):\n",
    "        string_learning_rate = str(learning_rate[i])  \n",
    "        string_learning_rate = string_learning_rate + \"_\" +str(beta[i]) + \"_\" +str(lamb[i])\n",
    "        if(algorithms_list[i] == \"pFedMe\" or algorithms_list[i] == \"pFedMe_p\"):\n",
    "            algorithms_list[i] = algorithms_list[i] + \"_\" + string_learning_rate + \"_\" + str(num_users) + \"u\" + \"_\" + str(batch_size[i]) + \"b\" + \"_\" +str(loc_ep1[i]) + \"_\"+ str(k[i])  + \"_\"+ str(personal_learning_rate[i])\n",
    "        else:\n",
    "            algorithms_list[i] = algorithms_list[i] + \"_\" + string_learning_rate + \"_\" + str(num_users) + \"u\" + \"_\" + str(batch_size[i]) + \"b\"  \"_\" +str(loc_ep1[i])\n",
    "        train_acc[i, :], train_loss[i, :], glob_acc[i, :] = np.array(\n",
    "            simple_read_data(dataset +\"_\"+ algorithms_list[i] + \"_avg\"))[:, :Numb_Glob_Iters]\n",
    "        algorithms_list[i] = algs_lbl[i]\n",
    "    return glob_acc, train_acc, train_loss\n",
    "\n",
    "def get_max_value_index(num_users=100, loc_ep1=5, Numb_Glob_Iters=10, lamb=[], learning_rate=[],beta=[],algorithms_list=[], batch_size=[], dataset=\"\", k= [] , personal_learning_rate = []):\n",
    "    Numb_Algs = len(algorithms_list)\n",
    "    glob_acc, train_acc, train_loss = get_training_data_value(num_users, loc_ep1, Numb_Glob_Iters, lamb, learning_rate, beta, algorithms_list, batch_size, dataset, k, personal_learning_rate)\n",
    "    for i in range(Numb_Algs):\n",
    "        print(\"Algorithm: \", algorithms_list[i], \"Max testing Accurancy: \", glob_acc[i].max(\n",
    "        ), \"Index: \", np.argmax(glob_acc[i]), \"local update:\", loc_ep1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_training_data_value(num_users=100, loc_ep1=5, Numb_Glob_Iters=10, lamb=0, learning_rate=0,beta=0,algorithms=\"\", batch_size=0, dataset=\"\", k= 0 , personal_learning_rate =0 ,times = 10):\n",
    "    train_acc = np.zeros((times, Numb_Glob_Iters))\n",
    "    train_loss = np.zeros((times, Numb_Glob_Iters))\n",
    "    glob_acc = np.zeros((times, Numb_Glob_Iters))\n",
    "    algorithms_list  = [algorithms] * times\n",
    "    for i in range(times):\n",
    "        string_learning_rate = str(learning_rate)  \n",
    "        string_learning_rate = string_learning_rate + \"_\" +str(beta) + \"_\" +str(lamb)\n",
    "        if(algorithms == \"pFedMe\" or algorithms == \"pFedMe_p\"):\n",
    "            algorithms_list[i] = algorithms_list[i] + \"_\" + string_learning_rate + \"_\" + str(num_users) + \"u\" + \"_\" + str(batch_size) + \"b\" + \"_\" +str(loc_ep1) + \"_\"+ str(k)  + \"_\"+ str(personal_learning_rate) +  \"_\" +str(i) \n",
    "        else:\n",
    "            algorithms_list[i] = algorithms_list[i] + \"_\" + string_learning_rate + \"_\" + str(num_users) + \"u\" + \"_\" + str(batch_size) + \"b\"  \"_\" +str(loc_ep1) +  \"_\" +str(i)\n",
    "\n",
    "        train_acc[i, :], train_loss[i, :], glob_acc[i, :] = np.array(\n",
    "            simple_read_data(dataset +\"_\"+ algorithms_list[i]))[:, :Numb_Glob_Iters]\n",
    "    return glob_acc, train_acc, train_loss\n",
    "\n",
    "def get_max_value_index_all(num_users=100, loc_ep1=5, Numb_Glob_Iters=10, lamb=0, learning_rate=0,beta=0, algorithms=\"\", batch_size=0, dataset=\"\", k= 0 , personal_learning_rate =0 ,times = 10):\n",
    "    glob_acc, train_acc, train_loss = get_all_training_data_value(num_users, loc_ep1, Numb_Glob_Iters, lamb, learning_rate, beta, algorithms, batch_size, dataset, k, personal_learning_rate)\n",
    "    for i in range(times):\n",
    "        print(\"Algorithm: \", algorithms, \"Max testing Accurancy: \", glob_acc[i].max(\n",
    "        ), \"Index: \", np.argmax(glob_acc[i]), \"local update:\", loc_ep1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nglob_acc, train_acc, train_loss = get_training_data_value(num_users=num_users,\\n                                                          loc_ep1=local_epochs,\\n                                                          Numb_Glob_Iters=800,\\n                                                          lamb=lambdas,\\n                                                          learning_rate=learning_rates,\\n                                                          beta=betas,\\n                                                          algorithms_list=algorithms,\\n                                                          batch_size=batch_sizes,\\n                                                          dataset=dataset,)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "glob_acc, train_acc, train_loss = get_training_data_value(num_users=num_users,\n",
    "                                                          loc_ep1=local_epochs,\n",
    "                                                          Numb_Glob_Iters=800,\n",
    "                                                          lamb=lambdas,\n",
    "                                                          learning_rate=learning_rates,\n",
    "                                                          beta=betas,\n",
    "                                                          algorithms_list=algorithms,\n",
    "                                                          batch_size=batch_sizes,\n",
    "                                                          dataset=dataset,)\n",
    "'''                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nglob_acc_all, train_acc_all, train_loss_all = get_all_training_data_value(num_users=num_users,\\n                            loc_ep1=local_epochs,\\n                            Numb_Glob_Iters=800,\\n                            lamb=lambdas,\\n                            learning_rate=learning_rates,\\n                            beta=betas,\\n                            algorithms=algorithms,\\n                            batch_size=batch_sizes,\\n                            dataset=dataset,\\n                            times=10)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "glob_acc_all, train_acc_all, train_loss_all = get_all_training_data_value(num_users=num_users,\n",
    "                            loc_ep1=local_epochs,\n",
    "                            Numb_Glob_Iters=800,\n",
    "                            lamb=lambdas,\n",
    "                            learning_rate=learning_rates,\n",
    "                            beta=betas,\n",
    "                            algorithms=algorithms,\n",
    "                            batch_size=batch_sizes,\n",
    "                            dataset=dataset,\n",
    "                            times=10)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [ \"pFedMe_p\",\"pFedMe\",\"PerAvg_p\",\"FedAvg\"]\n",
    "dataset = \"results_MLR/Mnist\"\n",
    "learning_rates = [0.01, 0.01, 0.03, 0.02]\n",
    "betas = [2.0, 2.0, 0.003, 1.0]\n",
    "lambdas = [15, 15, 15, 15]\n",
    "batch_sizes = [20, 20, 20, 20]\n",
    "num_users = 5\n",
    "local_epochs = [20, 20, 20, 20]\n",
    "\n",
    "K = [5,5,5,5]\n",
    "personal_learning_rate = [0.1,0.1,0.1,0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_MLR/Mnist_pFedMe_p_0.01_2.0_15_5u_20b_20_5_0.1_avg\n",
      "results_MLR/Mnist_pFedMe_0.01_2.0_15_5u_20b_20_5_0.1_avg\n",
      "results_MLR/Mnist_PerAvg_p_0.03_0.003_15_5u_20b_20_avg\n",
      "results_MLR/Mnist_FedAvg_0.02_1.0_15_5u_20b_20_avg\n",
      "Algorithm:  pFedMe_p Max testing Accurancy:  0.939389848812095 Index:  76 local update: 20\n",
      "Algorithm:  pFedMe Max testing Accurancy:  0.9194384449244062 Index:  250 local update: 20\n",
      "Algorithm:  PerAvg_p Max testing Accurancy:  0.9334773218142549 Index:  470 local update: 20\n",
      "Algorithm:  FedAvg Max testing Accurancy:  0.9249999999999998 Index:  743 local update: 20\n"
     ]
    }
   ],
   "source": [
    "get_max_value_index(num_users=num_users,\n",
    "                    loc_ep1=local_epochs,\n",
    "                    Numb_Glob_Iters=800,\n",
    "                    lamb=lambdas,\n",
    "                    learning_rate=learning_rates,\n",
    "                    beta=betas,\n",
    "                    algorithms_list=algorithms,\n",
    "                    batch_size=batch_sizes,\n",
    "                    dataset=dataset,\n",
    "                    k=K,\n",
    "                    personal_learning_rate=personal_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nalgorithms = \"FedAvg\"\\ndataset = \"Mnist\"\\nlearning_rates = 0.02\\nbetas = 1.0\\nlambdas = 15\\nbatch_sizes = 20\\nnum_users = 5\\nlocal_epochs = 20\\n\\nget_max_value_index_all(num_users=num_users,\\n                    loc_ep1=local_epochs,\\n                    Numb_Glob_Iters=800,\\n                    lamb=lambdas,\\n                    learning_rate=learning_rates,\\n                    beta=betas,\\n                    algorithms=algorithms,\\n                    batch_size=batch_sizes,\\n                    dataset=dataset)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "algorithms = \"FedAvg\"\n",
    "dataset = \"Mnist\"\n",
    "learning_rates = 0.02\n",
    "betas = 1.0\n",
    "lambdas = 15\n",
    "batch_sizes = 20\n",
    "num_users = 5\n",
    "local_epochs = 20\n",
    "\n",
    "get_max_value_index_all(num_users=num_users,\n",
    "                    loc_ep1=local_epochs,\n",
    "                    Numb_Glob_Iters=800,\n",
    "                    lamb=lambdas,\n",
    "                    learning_rate=learning_rates,\n",
    "                    beta=betas,\n",
    "                    algorithms=algorithms,\n",
    "                    batch_size=batch_sizes,\n",
    "                    dataset=dataset)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [ \"pFedMe_p\",\"pFedMe\",\"PerAvg_p\",\"FedAvg\"]\n",
    "dataset = \"results_DNN/Mnist\"\n",
    "learning_rates = [0.01, 0.01, 0.02, 0.02]\n",
    "betas = [2.0, 2.0, 0.001, 1.0]\n",
    "lambdas = [30, 30, 15, 15]\n",
    "batch_sizes = [20, 20, 20, 20]\n",
    "num_users = 5\n",
    "local_epochs = [20, 20, 20, 20]\n",
    "\n",
    "K = [5,5,5,5]\n",
    "personal_learning_rate = [0.05,0.05,0.05,0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_DNN/Mnist_pFedMe_p_0.01_2.0_30_5u_20b_20_5_0.05_avg\n",
      "results_DNN/Mnist_pFedMe_0.01_2.0_30_5u_20b_20_5_0.05_avg\n",
      "results_DNN/Mnist_PerAvg_p_0.02_0.001_15_5u_20b_20_avg\n",
      "results_DNN/Mnist_FedAvg_0.02_1.0_15_5u_20b_20_avg\n",
      "Algorithm:  pFedMe_p Max testing Accurancy:  0.9674946004319654 Index:  255 local update: 20\n",
      "Algorithm:  pFedMe Max testing Accurancy:  0.962392008639309 Index:  768 local update: 20\n",
      "Algorithm:  PerAvg_p Max testing Accurancy:  0.9415496760259179 Index:  794 local update: 20\n",
      "Algorithm:  FedAvg Max testing Accurancy:  0.9604481641468684 Index:  570 local update: 20\n"
     ]
    }
   ],
   "source": [
    "get_max_value_index(num_users=num_users,\n",
    "                    loc_ep1=local_epochs,\n",
    "                    Numb_Glob_Iters=800,\n",
    "                    lamb=lambdas,\n",
    "                    learning_rate=learning_rates,\n",
    "                    beta=betas,\n",
    "                    algorithms_list=algorithms,\n",
    "                    batch_size=batch_sizes,\n",
    "                    dataset=dataset,\n",
    "                    k=K,\n",
    "                    personal_learning_rate=personal_learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
